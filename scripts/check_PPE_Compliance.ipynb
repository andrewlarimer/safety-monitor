{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Objectives\n",
    "1. Get 50 frames from each video\n",
    "2. At a rate of 1 frame per second of video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import required packages\n",
    "import cv2\n",
    "import os\n",
    "import moviepy.editor as mpe\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "from collections import namedtuple\n",
    "import numpy as np\n",
    "from signalwire.rest import Client as signalwire_client\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Capture images from video stream \n",
    "\n",
    "The following snippet of code nneds to be called only if the predictions are fed as a video and the frames (pictures) need to be extracted from it.  If the predictions with bounding boxes are captured as a video stream, the images / frames are saved for further processing, which primarily includes checking PPE compliance. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Extract & Save Frames from Video\n",
    "\n",
    "As a first step, read in the file and extract the frames and save them for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vidcap = cv2.VideoCapture('prediction_animation.mp4')\n",
    "success,image = vidcap.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "(700, 1236, 3)\n"
     ]
    }
   ],
   "source": [
    "print(success)\n",
    "print(image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_SAVE_PATH='images/' # folder to save images in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "success = True\n",
    "while success:\n",
    "    success,image = vidcap.read()\n",
    "    cv2.imwrite(IMG_SAVE_PATH+\"frame%d.jpg\" % count, image)     # save frame as JPEG file\n",
    "    if cv2.waitKey(0) == 27:                     # exit if Escape is hit\n",
    "        break    \n",
    "    count += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Process video read frame/images\n",
    "\n",
    "Read the video file from the path and save the images to the specific folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "VID_PATH_GET='input_video/'\n",
    "VID_PATH_SAVE='video_images/' # folder to save images in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['prediction_animation.mp4']\n"
     ]
    }
   ],
   "source": [
    "# get all .mp4 files for processing\n",
    "lst=os.listdir(VID_PATH_GET) # folder with .mp4 files \n",
    "vidlst=sorted([i for i in lst if '.mp4' in i])\n",
    "print(vidlst)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Clean-up folder to hold images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[WinError 183] Cannot create a file when that file already exists: 'video_images/'\n",
      "Do you want to delete all .jpeg from directory? y/n y\n"
     ]
    }
   ],
   "source": [
    "# make/clear frame save dir\n",
    "try:\n",
    "    os.mkdir(VID_PATH_SAVE)\n",
    "except FileExistsError as f:\n",
    "    print(f)\n",
    "    pass\n",
    "    \n",
    "# clear out save directory for frames\n",
    "inpt=input('Do you want to delete all .jpeg from directory? y/n ')\n",
    "if inpt=='y': [os.remove(VID_PATH_SAVE+i) for i in os.listdir('video_images') if '.jpeg' in i]\n",
    "    #[os.remove(i) for i in os.listdir('video_images//') ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:12<00:00, 12.85s/it]\n"
     ]
    }
   ],
   "source": [
    "# get a 50 sec clip with one frame per second with some buffer to start (e.g 20 secs), if the vid is long enough\n",
    "max_segment_length=50; start=10\n",
    "\n",
    "err_lst,vid_proc=[],[] # list of vids not processed, list of processed vids\n",
    "\n",
    "counter=0\n",
    "for vid in tqdm(vidlst):\n",
    "    vid = vidlst[0]\n",
    "    video = mpe.VideoFileClip(VID_PATH_GET+vid)\n",
    "    start=1 if video.duration < max_segment_length else video.duration-max_segment_length\n",
    "    finish=max_segment_length+start if video.duration > max_segment_length+start else video.duration\n",
    "\n",
    "    for t in range(0,int(video.duration),max(1,int(video.duration/50))):\n",
    "        try:\n",
    "            video.save_frame(VID_PATH_SAVE+'{}_{}.jpeg'.\n",
    "                             format(vid.split('.mp4')[0].strip(), counter), t=t) # save frame at t=2 as JPEG\n",
    "            vid_proc.append((vid,': ',video.duration))\n",
    "        except:\n",
    "            err_lst.append('{} had OS error and was not processed'.format(vid))\n",
    "            pass\n",
    "\n",
    "        counter+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process 'Results' file to get objects with valid overlaps\n",
    "\n",
    "We are primarily looking to see if the person in the frame (assuming, they are at the construction site) have the safety vest and hard hat on them and this can be validated from the bounding box information of the objects.  Since safety vest and hardhats are worn by the person, we can make the assumption that the coordinates of the bounding box will have high overlap or intersection area (compared with the smaller object). \n",
    "\n",
    "The logic below takes this approach and identifies if the person in frame has a matching safety vest and/or hardhat identified.  There may be scenarios, where in the object in the frame is cut-off (because of the way the picture was taken) and so, the person may be identified, but the hard hat may not show up in the frame and so, the person will not get tagged as having a hard hat on them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to the fi\n",
    "VID_PATH_GET='input_video/'\n",
    "VID_PATH_SAVE='video_images/' # folder to save images in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define a named tuple to hold objects that need to be compared by their bounding box information\n",
    "Detection = namedtuple(\"Detection\", [\"Box1Category\", \"Box2Category\", \"bb_box1\", \"bb_box2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_BoundingBox_IOU_Overlap(boxA, boxB):\n",
    "    # determine the (x, y)-coordinates of the intersection rectangle\n",
    "    xA = max(boxA[0], boxB[0])\n",
    "    yA = max(boxA[1], boxB[1])\n",
    "    xB = min(boxA[2], boxB[2])\n",
    "    yB = min(boxA[3], boxB[3])\n",
    " \n",
    "    # compute the area of intersection rectangle\n",
    "    interArea = max(0, xB - xA + 1) * max(0, yB - yA + 1)\n",
    " \n",
    "    # compute the area of both the prediction and ground-truth\n",
    "    # rectangles\n",
    "    boxAArea = (boxA[2] - boxA[0] + 1) * (boxA[3] - boxA[1] + 1)\n",
    "    boxBArea = (boxB[2] - boxB[0] + 1) * (boxB[3] - boxB[1] + 1)\n",
    " \n",
    "    # compute the intersection over union by taking the intersection\n",
    "    # area and dividing it by the sum of prediction + ground-truth\n",
    "    # areas - the interesection area\n",
    "    iou = interArea / float(boxAArea + boxBArea - interArea)\n",
    "    percent_overlap = interArea / boxBArea\n",
    "    \n",
    "    #print(\"boxAArea: {}, boxBArea: {}, inter-area: {}, and iou: {}, and percent overlap: {}\".format(boxAArea, boxBArea, interArea, iou, percent_overlap))\n",
    " \n",
    "    # return the intersection over union value\n",
    "    return round(iou,4), round(percent_overlap,4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of how the data structure would look like\n",
    "object_detection = [\n",
    "    Detection(\"Person\", \"Vest\", [403, 237, 414, 264], [404, 239, 415, 255]),\n",
    "    Detection(\"Person\", \"Vest\", [403, 237, 414, 264], [446, 203, 452, 206]),\n",
    "    Detection(\"Person\", \"HardHat\", [403, 237, 414, 264], [407, 237, 413, 241]),\n",
    "    Detection(\"Person\", \"Vest\", [403, 237, 414, 264], [410, 263, 425, 275])\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for detection in object_detection:\n",
    "    iou = get_BoundingBox_IOU_Overlap(detection.bb_box1, detection.bb_box2)\n",
    "    #print(\"iou: \", iou)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read the results file for processing\n",
    "\n",
    "The results file holds information for objects detected, the confidence scores and the coordinate details etc.  For each person identified, we are trying to validate that they are having a safety vest and hard hat on them.  For this, we use the area of overlap and the IOU between the two bounding boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to the correct folder where the results file are located\n",
    "wd=os.path.dirname(os.path.abspath('__file__'))\n",
    "results_folder = '\\\\result_files'\n",
    "\n",
    "filenames = []\n",
    "\n",
    "for file in os.listdir(str(wd)+results_folder):\n",
    "    #print(file)\n",
    "    filenames.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function defined t fetch the extent of overlap between \n",
    "# two objects and their bounding boxes\n",
    "def get_object_overlap(parent_row, df_obj):\n",
    "    parent_overlap=[]\n",
    "    \n",
    "    parent_obj=[]\n",
    "    for sub_index, sub_row in df_obj.iterrows():\n",
    "        parent_obj.append(get_object_details(parent_row['Category'], sub_row['Category'], \n",
    "                                             parent_row['xmin'], parent_row['ymin'], parent_row['xmax'], parent_row['ymax'],\n",
    "                                             sub_row['xmin'], sub_row['ymin'], sub_row['xmax'], sub_row['ymax']))\n",
    "\n",
    "    iou_overlap = []\n",
    "    for detection in parent_obj:\n",
    "        iou, percent_overlap = get_BoundingBox_IOU_Overlap(detection.bb_box1, detection.bb_box2)\n",
    "        iou_overlap.append([iou, percent_overlap])\n",
    "    \n",
    "    #print(iou_overlap)\n",
    "    max_overlap=[0.0, 0.0]\n",
    "    \n",
    "    for result in iou_overlap:\n",
    "        if result[1] > max_overlap[1]:\n",
    "            max_overlap=result\n",
    "    \n",
    "    parent_overlap.append(max_overlap)\n",
    "    \n",
    "    return parent_overlap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_object_details(category1, category2, c1_xmin, c1_ymin, c1_xmax, c1_ymax, c2_xmin, c2_ymin, c2_xmax, c2_ymax):\n",
    "    return (Detection(category1, category2, [c1_xmin, c1_ymin, c1_xmax, c1_ymax], [c2_xmin, c2_ymin, c2_xmax, c2_ymax]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def has_overlap(row, overlap_threshold=0.35):\n",
    "    if (row['hardhat_overlap'][0] > 0) and (row['hardhat_overlap'][1] > overlap_threshold):\n",
    "        return \"Good match\"\n",
    "    elif (row['ymin'] < 144):\n",
    "        return \"Object not in frame\"\n",
    "    else:\n",
    "        return \"No match found\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get API key from local file (used for sending text messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAPIKeyFromFile(filename):\n",
    "    import imp\n",
    "    f = open(filename)\n",
    "    global val\n",
    "    val = imp.load_source('val', '', f)\n",
    "    f.close()\n",
    "\n",
    "# path to file with API-Key\n",
    "getAPIKeyFromFile('api_key.py')\n",
    "\n",
    "# the value is stored in val.signalwire_apikey "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_alert(message):\n",
    "    #FOREMAN_PHONE_NUMBER='+15044007414'\n",
    "    FOREMAN_PHONE_NUMBER='+15126298572'\n",
    "\n",
    "    #client = signalwire_client(\"97aa164c-bcd2-441f-aa28-aee2c522d71d\", os.environ['SIGNALWIRE_API_KEY'], signalwire_space_url = 'shrinkray.signalwire.com')\n",
    "    client = signalwire_client(\"97aa164c-bcd2-441f-aa28-aee2c522d71d\", val.signalwire_apikey, signalwire_space_url = 'shrinkray.signalwire.com')\n",
    "\n",
    "    message = client.messages.create(\n",
    "                                  from_='+15122290600',\n",
    "                                  body=message,\n",
    "                                  to=FOREMAN_PHONE_NUMBER\n",
    "                              )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define function to proces a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_files(filenames, threshold=0.35):\n",
    "    # set the counter for tracking number of frames\n",
    "    frame_count = 0\n",
    "    # set the counter to track non-compliant numbers\n",
    "    non_compliant_count = 0\n",
    "    total_noncompliant = 0\n",
    "    \n",
    "    for file in filenames:\n",
    "        frame_count += 1\n",
    "        # do processing specific to the file; read the result file\n",
    "        df = pd.read_csv('result_files/Sequence02_90.txt', sep=' ',header=None, usecols=[0, 1,2,3,4,5])\n",
    "        df.columns = ['Category', 'ConfidenceScore', 'xmin', 'ymin', 'xmax', 'ymax']\n",
    "        \n",
    "        # capture details specific to each category - person, safetyvest and hardhat\n",
    "        df_person = df[df['Category']=='person'].reset_index(drop=True)\n",
    "        df_safetyvest = df[df['Category']=='safetyvest'].reset_index(drop=True)\n",
    "        df_hardhat = df[df['Category']=='hardhat'].reset_index(drop=True)   \n",
    "\n",
    "        # get object details for person-safetyvest and person-hardhat (to get the overlap info between them)\n",
    "        person_hardhat_overlap = []\n",
    "        person_safetyvest_overlap = []\n",
    "\n",
    "        for p_index, p_row in df_person.iterrows():\n",
    "            parent_overlap = get_object_overlap(p_row, df_hardhat)\n",
    "            person_hardhat_overlap.append(parent_overlap[0])\n",
    "\n",
    "\n",
    "        for p_index, p_row in df_person.iterrows():\n",
    "            parent_overlap = get_object_overlap(p_row, df_safetyvest)\n",
    "            person_safetyvest_overlap.append(parent_overlap[0])\n",
    "\n",
    "        print(person_hardhat_overlap)\n",
    "        print(person_safetyvest_overlap)\n",
    "\n",
    "        df_combined = pd.concat([df_person, pd.DataFrame({'hardhat_overlap': person_hardhat_overlap, 'safetyvest_overlap': person_safetyvest_overlap})] ,axis=1)\n",
    "        print(df_combined)\n",
    "        \n",
    "        df_combined['hh_overlap'] = df_combined.apply(has_overlap, axis=1)\n",
    "        df_combined['sv_overlap'] = df_combined.apply(has_overlap, axis=1)\n",
    "        \n",
    "        df_matches = df_combined[~(df_combined['hh_overlap']=='Good match') & ~(df_combined['sv_overlap']=='Good match')]\n",
    "        if (df_matches.shape[0] > 1):\n",
    "            non_compliant_count += 1\n",
    "            total_noncompliant += 1\n",
    "        else:\n",
    "            # reset the counter \n",
    "            non_compliant_count = 0\n",
    "            \n",
    "        if (frame_count == 3):\n",
    "            # reset the frame count to restart at 0\n",
    "            frame_count = 0\n",
    "        else:\n",
    "            if (non_compliant_count >= 2):\n",
    "                send_alert('ATTN Safety Monitor suspects someone onsite is not wearing their PPE!')\n",
    "         \n",
    "        print(\"file: \", file, \" has been processed\")\n",
    "        print(\"Total frames read: {} and total non-compliant so far are: {}\", format(str(frame_count), str(non_compliant_count)))\n",
    "            \n",
    "            #print(\"More than one person not meeting PPE compliance\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.1212, 0.1766], [0.0455, 0.5], [0.0122, 0.0455], [0.0, 0.0], [0.1433, 1.0], [0.0736, 0.9524]]\n",
      "[[0.6148, 1.0], [0.4329, 1.0], [0.3852, 1.0], [0.3675, 1.0], [0.0372, 1.0], [0.3356, 0.9529]]\n",
      "  Category  ConfidenceScore  xmin  ymin  xmax  ymax   hardhat_overlap  \\\n",
      "0   person             0.73   466   142   513   202  [0.1212, 0.1766]   \n",
      "1   person             0.81   524   179   559   255     [0.0455, 0.5]   \n",
      "2   person             0.92   381   139   463   293  [0.0122, 0.0455]   \n",
      "3   person             0.95   276   136   360   305        [0.0, 0.0]   \n",
      "4   person             0.98   418   184   556   415     [0.1433, 1.0]   \n",
      "5   person             0.99     5   216   182   367  [0.0736, 0.9524]   \n",
      "\n",
      "  safetyvest_overlap  \n",
      "0      [0.6148, 1.0]  \n",
      "1      [0.4329, 1.0]  \n",
      "2      [0.3852, 1.0]  \n",
      "3      [0.3675, 1.0]  \n",
      "4      [0.0372, 1.0]  \n",
      "5   [0.3356, 0.9529]  \n",
      "file:  Sequence01_15.txt  has been processed\n",
      "Total frames read: {} and total non-compliant so far are: {} 1\n",
      "[[0.1212, 0.1766], [0.0455, 0.5], [0.0122, 0.0455], [0.0, 0.0], [0.1433, 1.0], [0.0736, 0.9524]]\n",
      "[[0.6148, 1.0], [0.4329, 1.0], [0.3852, 1.0], [0.3675, 1.0], [0.0372, 1.0], [0.3356, 0.9529]]\n",
      "  Category  ConfidenceScore  xmin  ymin  xmax  ymax   hardhat_overlap  \\\n",
      "0   person             0.73   466   142   513   202  [0.1212, 0.1766]   \n",
      "1   person             0.81   524   179   559   255     [0.0455, 0.5]   \n",
      "2   person             0.92   381   139   463   293  [0.0122, 0.0455]   \n",
      "3   person             0.95   276   136   360   305        [0.0, 0.0]   \n",
      "4   person             0.98   418   184   556   415     [0.1433, 1.0]   \n",
      "5   person             0.99     5   216   182   367  [0.0736, 0.9524]   \n",
      "\n",
      "  safetyvest_overlap  \n",
      "0      [0.6148, 1.0]  \n",
      "1      [0.4329, 1.0]  \n",
      "2      [0.3852, 1.0]  \n",
      "3      [0.3675, 1.0]  \n",
      "4      [0.0372, 1.0]  \n",
      "5   [0.3356, 0.9529]  \n",
      "file:  Sequence01_17.txt  has been processed\n",
      "Total frames read: {} and total non-compliant so far are: {} 2 \n",
      "[[0.1212, 0.1766], [0.0455, 0.5], [0.0122, 0.0455], [0.0, 0.0], [0.1433, 1.0], [0.0736, 0.9524]]\n",
      "[[0.6148, 1.0], [0.4329, 1.0], [0.3852, 1.0], [0.3675, 1.0], [0.0372, 1.0], [0.3356, 0.9529]]\n",
      "  Category  ConfidenceScore  xmin  ymin  xmax  ymax   hardhat_overlap  \\\n",
      "0   person             0.73   466   142   513   202  [0.1212, 0.1766]   \n",
      "1   person             0.81   524   179   559   255     [0.0455, 0.5]   \n",
      "2   person             0.92   381   139   463   293  [0.0122, 0.0455]   \n",
      "3   person             0.95   276   136   360   305        [0.0, 0.0]   \n",
      "4   person             0.98   418   184   556   415     [0.1433, 1.0]   \n",
      "5   person             0.99     5   216   182   367  [0.0736, 0.9524]   \n",
      "\n",
      "  safetyvest_overlap  \n",
      "0      [0.6148, 1.0]  \n",
      "1      [0.4329, 1.0]  \n",
      "2      [0.3852, 1.0]  \n",
      "3      [0.3675, 1.0]  \n",
      "4      [0.0372, 1.0]  \n",
      "5   [0.3356, 0.9529]  \n",
      "file:  Sequence01_23.txt  has been processed\n",
      "Total frames read: {} and total non-compliant so far are: {} 0  \n",
      "[[0.1212, 0.1766], [0.0455, 0.5], [0.0122, 0.0455], [0.0, 0.0], [0.1433, 1.0], [0.0736, 0.9524]]\n",
      "[[0.6148, 1.0], [0.4329, 1.0], [0.3852, 1.0], [0.3675, 1.0], [0.0372, 1.0], [0.3356, 0.9529]]\n",
      "  Category  ConfidenceScore  xmin  ymin  xmax  ymax   hardhat_overlap  \\\n",
      "0   person             0.73   466   142   513   202  [0.1212, 0.1766]   \n",
      "1   person             0.81   524   179   559   255     [0.0455, 0.5]   \n",
      "2   person             0.92   381   139   463   293  [0.0122, 0.0455]   \n",
      "3   person             0.95   276   136   360   305        [0.0, 0.0]   \n",
      "4   person             0.98   418   184   556   415     [0.1433, 1.0]   \n",
      "5   person             0.99     5   216   182   367  [0.0736, 0.9524]   \n",
      "\n",
      "  safetyvest_overlap  \n",
      "0      [0.6148, 1.0]  \n",
      "1      [0.4329, 1.0]  \n",
      "2      [0.3852, 1.0]  \n",
      "3      [0.3675, 1.0]  \n",
      "4      [0.0372, 1.0]  \n",
      "5   [0.3356, 0.9529]  \n",
      "file:  Sequence01_9.txt  has been processed\n",
      "Total frames read: {} and total non-compliant so far are: {} 1   \n",
      "[[0.1212, 0.1766], [0.0455, 0.5], [0.0122, 0.0455], [0.0, 0.0], [0.1433, 1.0], [0.0736, 0.9524]]\n",
      "[[0.6148, 1.0], [0.4329, 1.0], [0.3852, 1.0], [0.3675, 1.0], [0.0372, 1.0], [0.3356, 0.9529]]\n",
      "  Category  ConfidenceScore  xmin  ymin  xmax  ymax   hardhat_overlap  \\\n",
      "0   person             0.73   466   142   513   202  [0.1212, 0.1766]   \n",
      "1   person             0.81   524   179   559   255     [0.0455, 0.5]   \n",
      "2   person             0.92   381   139   463   293  [0.0122, 0.0455]   \n",
      "3   person             0.95   276   136   360   305        [0.0, 0.0]   \n",
      "4   person             0.98   418   184   556   415     [0.1433, 1.0]   \n",
      "5   person             0.99     5   216   182   367  [0.0736, 0.9524]   \n",
      "\n",
      "  safetyvest_overlap  \n",
      "0      [0.6148, 1.0]  \n",
      "1      [0.4329, 1.0]  \n",
      "2      [0.3852, 1.0]  \n",
      "3      [0.3675, 1.0]  \n",
      "4      [0.0372, 1.0]  \n",
      "5   [0.3356, 0.9529]  \n",
      "file:  Sequence02_90.txt  has been processed\n",
      "Total frames read: {} and total non-compliant so far are: {} 2    \n",
      "[[0.1212, 0.1766], [0.0455, 0.5], [0.0122, 0.0455], [0.0, 0.0], [0.1433, 1.0], [0.0736, 0.9524]]\n",
      "[[0.6148, 1.0], [0.4329, 1.0], [0.3852, 1.0], [0.3675, 1.0], [0.0372, 1.0], [0.3356, 0.9529]]\n",
      "  Category  ConfidenceScore  xmin  ymin  xmax  ymax   hardhat_overlap  \\\n",
      "0   person             0.73   466   142   513   202  [0.1212, 0.1766]   \n",
      "1   person             0.81   524   179   559   255     [0.0455, 0.5]   \n",
      "2   person             0.92   381   139   463   293  [0.0122, 0.0455]   \n",
      "3   person             0.95   276   136   360   305        [0.0, 0.0]   \n",
      "4   person             0.98   418   184   556   415     [0.1433, 1.0]   \n",
      "5   person             0.99     5   216   182   367  [0.0736, 0.9524]   \n",
      "\n",
      "  safetyvest_overlap  \n",
      "0      [0.6148, 1.0]  \n",
      "1      [0.4329, 1.0]  \n",
      "2      [0.3852, 1.0]  \n",
      "3      [0.3675, 1.0]  \n",
      "4      [0.0372, 1.0]  \n",
      "5   [0.3356, 0.9529]  \n",
      "file:  Sequence02_94.txt  has been processed\n",
      "Total frames read: {} and total non-compliant so far are: {} 0     \n"
     ]
    }
   ],
   "source": [
    "threshold_value = 0.35\n",
    "\n",
    "process_files(filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print Counts\n",
    "\n",
    "The function below helps to compute the extent of overlap say between the bounding boxes for person and safety vest or for person and hardhat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
